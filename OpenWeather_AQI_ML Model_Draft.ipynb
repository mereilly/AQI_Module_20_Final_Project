{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36993c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding library dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sql alchemy / pandas methods (maybe read_sql)\n",
    "# from OpenWeather_AQI_DB_Final import pollutants_data_table_df, AQI_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0560852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>AQI</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NH3</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-27 05:00:00</td>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>1</td>\n",
       "      <td>195.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>54.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1606453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-27 06:00:00</td>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>1</td>\n",
       "      <td>196.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>56.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1606456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-27 07:00:00</td>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>1</td>\n",
       "      <td>198.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>57.94</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1606460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-27 08:00:00</td>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>1</td>\n",
       "      <td>198.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1606464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-27 09:00:00</td>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>1</td>\n",
       "      <td>198.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1606467600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date State   Latitude   Longitude  AQI      CO   NO   NO2  \\\n",
       "0  2020-11-27 05:00:00    AK  63.588753 -154.493062    1  195.27  0.0  0.03   \n",
       "1  2020-11-27 06:00:00    AK  63.588753 -154.493062    1  196.93  0.0  0.03   \n",
       "2  2020-11-27 07:00:00    AK  63.588753 -154.493062    1  198.60  0.0  0.03   \n",
       "3  2020-11-27 08:00:00    AK  63.588753 -154.493062    1  198.60  0.0  0.03   \n",
       "4  2020-11-27 09:00:00    AK  63.588753 -154.493062    1  198.60  0.0  0.03   \n",
       "\n",
       "      O3   SO2  PM2_5  PM10  NH3          dt  \n",
       "0  54.36  0.06    0.5  0.54  0.0  1606453200  \n",
       "1  56.51  0.06    0.5  0.54  0.0  1606456800  \n",
       "2  57.94  0.07    0.5  0.54  0.0  1606460400  \n",
       "3  58.65  0.07    0.5  0.54  0.0  1606464000  \n",
       "4  58.65  0.07    0.5  0.54  0.0  1606467600  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store CSV into DataFrame\n",
    "# Read in data and display first 5 rows\n",
    "AQI_data = pd.read_csv('Resources/AQI_data.csv')\n",
    "AQI_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d93da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26560, 14)\n"
     ]
    }
   ],
   "source": [
    "print(AQI_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb7e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for each column\n",
    "#All cells are full, verifying there aren't gaps/missing values to clean/remove associated values\n",
    "AQI_copy = AQI_data\n",
    "# Labels are the values we want to predict\n",
    "labels = AQI_data['AQI']\n",
    "# Features are the values we want to evaluate in reference to the output label\n",
    "features = AQI_data.drop(['Date', 'AQI', 'State','Latitude', 'Longitude', 'dt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caea1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, random_state=1)\n",
    "# test_size = 0.25 or another test size could be added if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b43293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NH3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19538</th>\n",
       "      <td>250.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.98</td>\n",
       "      <td>147.34</td>\n",
       "      <td>0.90</td>\n",
       "      <td>27.67</td>\n",
       "      <td>29.04</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21960</th>\n",
       "      <td>247.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.51</td>\n",
       "      <td>83.69</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19630</th>\n",
       "      <td>393.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.30</td>\n",
       "      <td>130.18</td>\n",
       "      <td>1.43</td>\n",
       "      <td>55.22</td>\n",
       "      <td>64.18</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14724</th>\n",
       "      <td>247.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.28</td>\n",
       "      <td>41.49</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13708</th>\n",
       "      <td>213.62</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.84</td>\n",
       "      <td>45.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>347.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>24.68</td>\n",
       "      <td>89.41</td>\n",
       "      <td>5.25</td>\n",
       "      <td>18.59</td>\n",
       "      <td>20.53</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>191.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>68.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.09</td>\n",
       "      <td>10.19</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>150.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>77.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>257.02</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.07</td>\n",
       "      <td>118.73</td>\n",
       "      <td>4.35</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>198.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>74.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19920 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CO    NO    NO2      O3   SO2  PM2_5   PM10   NH3\n",
       "19538  250.34  0.05   0.98  147.34  0.90  27.67  29.04  1.54\n",
       "21960  247.00  0.00   3.51   83.69  0.49   1.56   2.01  0.64\n",
       "19630  393.87  0.14   1.30  130.18  1.43  55.22  64.18  4.81\n",
       "14724  247.00  0.00   4.28   41.49  0.04   1.49   2.28  1.82\n",
       "13708  213.62  0.02   4.84   45.06  0.17   2.68   4.11  0.82\n",
       "...       ...   ...    ...     ...   ...    ...    ...   ...\n",
       "10955  347.14  0.29  24.68   89.41  5.25  18.59  20.53  1.44\n",
       "17289  191.93  0.00   3.04   68.67  0.32   8.09  10.19  2.47\n",
       "5192   150.20  0.00   0.14   77.96  0.02   0.50   0.54  0.00\n",
       "12172  257.02  0.41   4.07  118.73  4.35   8.37   8.93  0.22\n",
       "235    198.60  0.00   0.13   74.39  0.07   0.50   0.50  0.00\n",
       "\n",
       "[19920 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the output of the training split\n",
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5665e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2_5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NH3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8652</th>\n",
       "      <td>427.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>35.64</td>\n",
       "      <td>25.75</td>\n",
       "      <td>9.54</td>\n",
       "      <td>11.50</td>\n",
       "      <td>12.74</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23863</th>\n",
       "      <td>213.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.64</td>\n",
       "      <td>62.94</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>220.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>63.66</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12587</th>\n",
       "      <td>423.91</td>\n",
       "      <td>0.37</td>\n",
       "      <td>31.19</td>\n",
       "      <td>74.39</td>\n",
       "      <td>5.31</td>\n",
       "      <td>6.66</td>\n",
       "      <td>7.68</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>283.72</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.60</td>\n",
       "      <td>124.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>5.21</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24195</th>\n",
       "      <td>191.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>82.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25369</th>\n",
       "      <td>247.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.03</td>\n",
       "      <td>23.60</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>340.46</td>\n",
       "      <td>5.98</td>\n",
       "      <td>21.42</td>\n",
       "      <td>54.36</td>\n",
       "      <td>16.69</td>\n",
       "      <td>19.62</td>\n",
       "      <td>22.32</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17506</th>\n",
       "      <td>190.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>47.92</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.37</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>280.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.22</td>\n",
       "      <td>60.08</td>\n",
       "      <td>11.33</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CO    NO    NO2      O3    SO2  PM2_5   PM10   NH3\n",
       "8652   427.25  0.16  35.64   25.75   9.54  11.50  12.74  0.90\n",
       "23863  213.62  0.44   2.64   62.94   0.68   1.69   2.11  0.36\n",
       "2257   220.30  0.00   0.93   63.66   0.15   0.50   0.50  0.02\n",
       "12587  423.91  0.37  31.19   74.39   5.31   6.66   7.68  1.63\n",
       "12339  283.72  0.44   3.60  124.45   3.10   5.21   6.07  0.57\n",
       "...       ...   ...    ...     ...    ...    ...    ...   ...\n",
       "24195  191.93  0.00   2.01   82.25   0.50   0.88   1.72  0.09\n",
       "25369  247.00  0.00  10.03   23.60   1.76   4.85   5.55  0.09\n",
       "7759   340.46  5.98  21.42   54.36  16.69  19.62  22.32  0.38\n",
       "17506  190.26  0.00   2.36   47.92   0.20   2.37   3.45  2.41\n",
       "8277   280.38  0.00  14.22   60.08  11.33   6.97   7.85  1.33\n",
       "\n",
       "[6640 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Evaluating the output of the testing split\n",
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c459da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features so that varying data ranges can be comparable \n",
    "scaler = StandardScaler().fit(features_train)\n",
    "features_train_scaled = scaler.transform(features_train)\n",
    "features_test_scaled = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443a72c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.9996987951807229\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 600 decision trees\n",
    "rclf = RandomForestClassifier(n_estimators = 600, random_state = 7)\n",
    "# Train the model on training data\n",
    "rclf.fit(features_train_scaled, labels_train)\n",
    "\n",
    "\n",
    "print(f'Training Score: {rclf.score(features_train_scaled, labels_train)}')\n",
    "print(f'Testing Score: {rclf.score(features_test_scaled, labels_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe99e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.01 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rclf.predict(features_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - labels_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1411cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.46 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = (errors / labels_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690d89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NH3', 0.019230926950276037),\n",
       " ('NO', 0.028174127006549667),\n",
       " ('CO', 0.03102901636446812),\n",
       " ('SO2', 0.040378552486780545),\n",
       " ('NO2', 0.044957510629605686),\n",
       " ('PM10', 0.14686302450271146),\n",
       " ('PM2_5', 0.22440296294725717),\n",
       " ('O3', 0.4649638791123513)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating impact importance of the different features (i.e. pollutants relavance on the AQI)\n",
    "feature_importances = rclf.feature_importances_\n",
    "results = sorted(zip(features.columns, rclf.feature_importances_), key = lambda x: x[1])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e48517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The goal here is to make a visualization with plotly showing the importance of the pollutants on the AQI score\n",
    "\n",
    "cols = [r[0] for r in results]\n",
    "width = [r[1] for r in results]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(5,5)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ae1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Considering another classifier model\n",
    "\n",
    "# X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_features), y_train_labels, random_state=1)\n",
    "# scaler = StandardScaler().fit(X_selected_train)\n",
    "# X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "# X_selected_test_scaled = scaler.transform(X_selected_test)\n",
    "\n",
    "# rclf = LogisticRegression().fit(X_train_features, y_train)\n",
    "# print(f'Training Score: {rclf.score(X_train_features, y_train_labels)}')\n",
    "# print(f'Testing Score: {rclf.score(X_test_features, y_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query using different fileters from databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Considering AdaBoost CLassifier\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "#   from sklearn.datasets import make_classification\n",
    "#   X, y = make_classification(n_samples=1000, n_features=4,\n",
    "# ...                            n_informative=2, n_redundant=0,\n",
    "# ...                            random_state=0, shuffle=False)\n",
    "#   clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "#   clf.fit(X, y)\n",
    "# AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "#   clf.predict([[0, 0, 0, 0]])\n",
    "# array([1])\n",
    "#   clf.score(X, y)\n",
    "# 0.983..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)[source]¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7efa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy as np\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "# y = np.array([1, 1, 2, 2])\n",
    "# from sklearn.svm import SVC\n",
    "# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "# clf.fit(X, y)\n",
    "#Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "#                ('svc', SVC(gamma='auto'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565a7013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/michelle/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/michelle/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in /Users/michelle/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages (from xgboost) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d4bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/michelle/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB\n",
      "    libxgboost-1.3.3           |       h23ab428_0         1.2 MB\n",
      "    py-xgboost-1.3.3           |   py38hecd8cb5_0         136 KB\n",
      "    xgboost-1.3.3              |   py38hecd8cb5_0          23 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         pkgs/main/osx-64::libxgboost-1.3.3-h23ab428_0\n",
      "  py-xgboost         pkgs/main/osx-64::py-xgboost-1.3.3-py38hecd8cb5_0\n",
      "  xgboost            pkgs/main/osx-64::xgboost-1.3.3-py38hecd8cb5_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libxgboost-1.3.3     | 1.2 MB    | ##################################### | 100% \n",
      "py-xgboost-1.3.3     | 136 KB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "xgboost-1.3.3        | 23 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1abfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n"
     ]
    }
   ],
   "source": [
    "# check xgboost version? Cofused by this error, unable to try associated classifier model - see sample below\n",
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test classification dataset\n",
    "# from sklearn.datasets import make_classification\n",
    "# # define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# # summarize the dataset\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3280a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michelle/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Predicted Class: 1\n",
      "[19:52:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make predictions using xgboost for classification\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]\n",
    "row = asarray([row])\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])\n",
    "\n",
    "# make predictions using xgboost for classification\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]\n",
    "row = asarray([row])\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37974fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
